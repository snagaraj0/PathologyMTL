import numpy as np
import os
import sys
import glob
import cv2
import PIL
import random
import skimage.io
import matplotlib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#Misc imports
from sklearn.model_selection import StratifiedKFold
from tqdm import tqdm
import albumentations
import time
import glob

#Torch imports
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader, Dataset
from torch.utils.data.sampler import RandomSampler, SequentialSampler


class UNetDataLoader(Dataset):
    def __init__(self, df, image_size, n_tiles=36, transforms=None):
        self.df = df.reset_index(drop=True)
        self.image_size = image_size
        self.n_tiles = n_tiles
        self.transform = transforms

    def __len__(self):
        return len(self.df)
    
    # Custom get item function
    def __getitem__(self, idx):
        if idx > len(self.df):
            idx = len(self.df) - 1

        # Get Image Patches
        img_dir_path = os.path.join(data_folder, self.df.iloc[idx]['image_id'])
        image_tensors = []
        for patch in glob.glob(img_dir_path + "/*"):
            curr_img = cv2.imread(patch)
            curr_img_rgb = cv2.cvtColor(curr_img, cv2.COLOR_BGR2RGB)
            # Transpose from 1, H, W, C to 1, C, H, W
            curr_img_tensor = curr_img_rgb.transpose(2,0,1)
            image_tensors.append(curr_img_tensor)

        rows = int(np.sqrt(self.n_tiles))
        # C x H x W
        imgs = np.zeros((3, self.image_size * rows, self.image_size * rows))
        for h in range(rows):
            for w in range(rows):
                curr_idx = h * rows + w
                curr_img = image_tensors[curr_idx]
                if self.transform is not None:
                   curr_img = self.transform(image=curr_img)['image']
                h_scaled = h * self.image_size
                w_scaled = w * self.image_size
                imgs[:, h_scaled : h_scaled + self.image_size, w_scaled : w_scaled + self.image_size] = curr_img

        if self.transform is not None:
           imgs = self.transform(image=imgs)['image']
        imgs = imgs.astype(np.float64)
        imgs /= 255

        # Get Mask Patches
        mask_dir_path = os.path.join(masks_path, self.df.iloc[idx]['image_id'])
        mask_tensors = []
        for patch in glob.glob(mask_dir_path + "/*"):
            curr_mask = cv2.imread(patch)
            # Transpose from H, W, C to C, H, W
            curr_mask_tensor = curr_mask.transpose(2,0,1)

            # Get Channel 1 -> 1, H, W
            curr_mask_tensor = torch.tensor(curr_img_tensor)[0]
            
            # Transform to scale 0, 1, 2
            curr_mask_tensor = torch.where(curr_mask_tensor <= 1, curr_mask_tensor, torch.where(curr_mask_tensor <= 2, 1, 2))
            
            # Turn into 1 hot -> 3, H, W
            curr_mask_tensor = F.one_hot(curr_mask_tensor.squeeze(0), num_classes=3)

            # Add to list
            mask_tensors.append(curr_mask_tensor)

        rows = int(np.sqrt(self.n_tiles))
        # C x H x W
        masks = torch.zeros((3, self.image_size * rows, self.image_size * rows))
        for h in range(rows):
            for w in range(rows):
                curr_idx = h * rows + w
                curr_mask = mask_tensors[curr_idx]
                h_scaled = h * self.image_size
                w_scaled = w * self.image_size
                masks[:, h_scaled : h_scaled + self.image_size, w_scaled : w_scaled + self.image_size] = curr_img

        masks = masks.astype(np.float64)

        return torch.tensor(imgs), masks
    




